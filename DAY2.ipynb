{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "数据分析报告\n",
    "\n",
    "1.背景介绍（对数据的描述）\n",
    "2.分析过程（数据清洗/数据可视化/结论）（btw展现关系的话，热力图是个好东西（展现很多linear correlation））\n",
    "3.制定策略（发现关系之后就可以开始找策略啦，比如说在国外可能11/12月的票房更高）\n",
    "4.改进（数据集不够全/方法不够rigorous etc）\n",
    "\n",
    "模型与算法（Machine Learning）\n",
    ":C tired. tireddddd\n",
    " \n",
    "模型的性能判定\n",
    "1.评判指标\n",
    "    1.分类模型\n",
    "        精准率、召回率、F1分数\n",
    "    2.回归模型\n",
    "2.数据集\n",
    "    1.训练集\n",
    "    2.验证集\n",
    "    3.测试集\n",
    "3.模型验证\n",
    "\n",
    "Precision: 真阳性/（真阳性+假阳性）\n",
    "Recall：真阳性/（真阳性+假阴性）\n",
    "F1就是2*Precision+Recall/（准确率+召回率）\n",
    "\n",
    "影响模型性能的因素：\n",
    "1.算法（理论基础/近似模拟（Tayler Series））\n",
    "2.工程（算法实现/算力应用/系统工程）\n",
    "3.数据（特征筛选/编码/归一化）\n",
    "\n",
    "Voice/Speech Recognition\n",
    "\n",
    "ASR（1）：音频信号匹配\n",
    "1952，Bell Lab，Audrey\n",
    "ASR（2）：机器学习模型\n",
    "语音信号处理：FFT；\n",
    "语音特征提取；\n",
    "声学模型：GMM/HMM\n",
    "语言模型：N-Gram\n",
    "ASR（3）：深度学习模型\n",
    "Raw Audio-->Feature Extraction-->Acoustic Model(NNET3)-->Language Model-->Output\n",
    "\n",
    "用户意图识别，\n",
    "    1.基于规则：关键字/词典\n",
    "    2.基于模型：文本分类/分本相似度\n",
    "\n",
    "文本相似度：文本嵌入将文本转化为向量/计算文本向量的距离\n",
    "\n",
    "人工智能技术落地漏斗模型：\n",
    "场景>问题>任务>模型\n",
    "\n",
    "选取现有模型，\n",
    "通用模型/相同领域相同任务/不同领域相同任务\n",
    "\n",
    "模型的局限：直接完成任务，间接解决问题；各类指标不可能==100%;针对特定样本，无法直接控制结果\n",
    "\n",
    "无监督学习：\n",
    "1.Clustering，给训练数据X，学习数据的隐含结构，给数据分组（没有正确答案、自主发现规律）\n",
    "2.降低纬度：把M纬度数据映射到K维，尽可能保留原数据的信息；降低算法计算量、方便可视化\n",
    "\n",
    "半监督学习：\n",
    "1.利用标注数据训练初始模型\n",
    "2.利用出世模型给无标签数据打标签\n",
    "3.将新的弱标签数据加入有标签的数据机，重新训练模型\n",
    "\n",
    "强化学习：\n",
    "给予环境信息进行行动，去的最大化的预期利益。\n",
    "不同于监督和无监督学习，强化学习会延迟给出反馈。\n",
    "弱反馈\n",
    "主要应用在对弈，游戏，和自动驾驶等领域。\n",
    "要有一个完备的规则，不用标数据，让模型随机做action，根据规则给reward。\n",
    "\n",
    "联邦学习：Collaborative Learning\n",
    "是一种保护数据和隐私的方法\n",
    "用一种去中心化的设备联合进行模型训练\n",
    "共享梯度、不共享数据\n",
    "\n",
    "机器学习的流程：\n",
    "1）数据准备：数据的预处理、收集数据、清洗数据、标注数据；构建数据的向量空间模型（将文本/图片/音频/视频等格式的数据转化为向量），并进行数据正规化or标准化，将构建好的向量划分为训练集、验证集、测试集\n",
    "2）训练：将训练集输入给训练程序，进行运算；训练程序的核心是算法，所有输入的向量数据都会按该训练程序所依据的算法进行运算，训练程序输出的结果，就是模型                      \n",
    "3）测试：将测试集数据输入给训练获得的模型，得到预测结果，再将预测结果与数据的真实值进行比较/评价               \n",
    "4）部署：封装成为APIetc，放到服务端进行调用\n",
    "\n",
    "数据的标注：人工/半自动     \n",
    "打标签的几个原则：        \n",
    "1.先建立一个标注的准则，再开始标注。                \n",
    "2.保证数据标注的一致性（Very Important），不同的标注人员应该能对标注规则达成共识。\n",
    "3.如果某些数据无法标注，可以直接标记为“无法标注”，不需要强行标注到某一类（这样会降低数据准确度）。                                   \n",
    "4.如有条件可以交叉标注进一步提升标注质量和一致性。       \n",
    "5.标注人员直接应该定期交流，优化标注标准和一些edge cases的处理方式。      \n",
    "\n",
    "降低数据标注量的探索：\n",
    "1.学习数据的内在特征  \n",
    "    1.聚类分析       \n",
    "    2.BERT类语言模型     \n",
    "    3.CPC（Contrastive Predictive Coding）   \n",
    "2.利用已有数据学习通用特征    \n",
    "    1.多任务学习        \n",
    "    2.迁移学习（学习类似的）      \n",
    "    3.衍生网络        \n",
    "    4.Fast-shot Learning（Zero-shot learning/match-network/元学习）         \n",
    "3.其他       \n",
    "    1.Auto ML      \n",
    " \n",
    "语言模型-BERT Mask Language Model\n",
    "-随机mask一些字符，挡住一两个字，重组变成输入，mask的字变成label。\n",
    "-Embedding to vocab+ softmax\n",
    "-所以就无敌了\n",
    "\n",
    "\n",
    "一些要注意的问题 \n",
    "1.数据的代表性（Training Set/Validation Set都要代表数据） \n",
    "2.数据的冗余 \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 数据分析报告"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.背景介绍（对数据的描述）\n",
    "2.分析过程（数据清洗/数据可视化/结论）（btw展现关系的话，热力图是个好东西（展现很多linear correlation））\n",
    "3.制定策略（发现关系之后就可以开始找策略啦，比如说在国外可能11/12月的票房更高）\n",
    "4.改进（数据集不够全/方法不够rigorous etc）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 模型与训练"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "模型与算法（Machine Learning）\n",
    ":C tired. tireddddd\n",
    " \n",
    "模型的性能判定\n",
    "1.评判指标\n",
    "    1.分类模型\n",
    "        精准率、召回率、F1分数\n",
    "    2.回归模型\n",
    "2.数据集\n",
    "    1.训练集\n",
    "    2.验证集\n",
    "    3.测试集\n",
    "3.模型验证\n",
    "\n",
    "Precision: 真阳性/（真阳性+假阳性）\n",
    "Recall：真阳性/（真阳性+假阴性）\n",
    "F1就是2*Precision+Recall/（准确率+召回率）\n",
    "\n",
    "影响模型性能的因素：\n",
    "1.算法（理论基础/近似模拟（Tayler Series））\n",
    "2.工程（算法实现/算力应用/系统工程）\n",
    "3.数据（特征筛选/编码/归一化）\n",
    "\n",
    "Voice/Speech Recognition\n",
    "\n",
    "ASR（1）：音频信号匹配\n",
    "1952，Bell Lab，Audrey\n",
    "ASR（2）：机器学习模型\n",
    "语音信号处理：FFT；\n",
    "语音特征提取；\n",
    "声学模型：GMM/HMM\n",
    "语言模型：N-Gram\n",
    "ASR（3）：深度学习模型\n",
    "Raw Audio-->Feature Extraction-->Acoustic Model(NNET3)-->Language Model-->Output\n",
    "\n",
    "用户意图识别，\n",
    "    1.基于规则：关键字/词典\n",
    "    2.基于模型：文本分类/分本相似度\n",
    "\n",
    "文本相似度：文本嵌入将文本转化为向量/计算文本向量的距离\n",
    "\n",
    "人工智能技术落地漏斗模型：\n",
    "场景>问题>任务>模型\n",
    "\n",
    "选取现有模型，\n",
    "通用模型/相同领域相同任务/不同领域相同任务\n",
    "\n",
    "模型的局限：直接完成任务，间接解决问题；各类指标不可能==100%;针对特定样本，无法直接控制结果\n",
    "\n",
    "无监督学习：\n",
    "1.Clustering，给训练数据X，学习数据的隐含结构，给数据分组（没有正确答案、自主发现规律）\n",
    "2.降低纬度：把M纬度数据映射到K维，尽可能保留原数据的信息；降低算法计算量、方便可视化\n",
    "\n",
    "半监督学习：\n",
    "1.利用标注数据训练初始模型\n",
    "2.利用出世模型给无标签数据打标签\n",
    "3.将新的弱标签数据加入有标签的数据机，重新训练模型\n",
    "\n",
    "强化学习：\n",
    "给予环境信息进行行动，去的最大化的预期利益。\n",
    "不同于监督和无监督学习，强化学习会延迟给出反馈。\n",
    "弱反馈\n",
    "主要应用在对弈，游戏，和自动驾驶等领域。\n",
    "要有一个完备的规则，不用标数据，让模型随机做action，根据规则给reward。\n",
    "\n",
    "联邦学习：Collaborative Learning\n",
    "是一种保护数据和隐私的方法\n",
    "用一种去中心化的设备联合进行模型训练\n",
    "共享梯度、不共享数据\n",
    "\n",
    "机器学习的流程：\n",
    "1）数据准备：数据的预处理、收集数据、清洗数据、标注数据；构建数据的向量空间模型（将文本/图片/音频/视频等格式的数据转化为向量），并进行数据正规化or标准化，将构建好的向量划分为训练集、验证集、测试集\n",
    "2）训练：将训练集输入给训练程序，进行运算；训练程序的核心是算法，所有输入的向量数据都会按该训练程序所依据的算法进行运算，训练程序输出的结果，就是模型                      \n",
    "3）测试：将测试集数据输入给训练获得的模型，得到预测结果，再将预测结果与数据的真实值进行比较/评价               \n",
    "4）部署：封装成为APIetc，放到服务端进行调用\n",
    "\n",
    "数据的标注：人工/半自动     \n",
    "打标签的几个原则：        \n",
    "1.先建立一个标注的准则，再开始标注。                \n",
    "2.保证数据标注的一致性（Very Important），不同的标注人员应该能对标注规则达成共识。\n",
    "3.如果某些数据无法标注，可以直接标记为“无法标注”，不需要强行标注到某一类（这样会降低数据准确度）。                                   \n",
    "4.如有条件可以交叉标注进一步提升标注质量和一致性。       \n",
    "5.标注人员直接应该定期交流，优化标注标准和一些edge cases的处理方式。      \n",
    "\n",
    "降低数据标注量的探索：\n",
    "1.学习数据的内在特征  \n",
    "    1.聚类分析       \n",
    "    2.BERT类语言模型     \n",
    "    3.CPC（Contrastive Predictive Coding）   \n",
    "2.利用已有数据学习通用特征    \n",
    "    1.多任务学习        \n",
    "    2.迁移学习（学习类似的）      \n",
    "    3.衍生网络        \n",
    "    4.Fast-shot Learning（Zero-shot learning/match-network/元学习）         \n",
    "3.其他       \n",
    "    1.Auto ML      \n",
    " \n",
    "语言模型-BERT Mask Language Model\n",
    "-随机mask一些字符，挡住一两个字，重组变成输入，mask的字变成label。\n",
    "-Embedding to vocab+ softmax\n",
    "-所以就无敌了\n",
    "\n",
    "Contrastive Predictive Coding\n",
    "-用上半张图片predict下半张图片\n",
    "\n",
    "半监督学习：自学习；后来有了主动学习：Active Machine Learning\n",
    "Raw，unlabelled data，通过一个active learner-->把“难的”数据发给标注员，剩下的发给机器。利用自己标注的来train，之后通过自己train的来标注？之后再train。\n",
    "\n",
    "多任务学习，TaskA，TaskB，TaskC，同一个基础模型，三个不同的输出。之后搞出来一个task-specific layers。他们有shared layers。\n",
    "元学习，去学习一个可以学习别人的machine/program\n",
    "\n",
    "\n",
    "一些要注意的问题 \n",
    "1.数据的代表性（Training Set/Validation Set都要代表数据） \n",
    "2.数据的冗余 \n",
    "Few Shot Learning,求mean来进行classify\n",
    "\n",
    "数据预处理\n",
    "1.数据质量评估，筛选\n",
    "2.将原属数据召唤为矩阵\n",
    "3.对数据标准化、规范化\n",
    "4.特征工程\n",
    "5.数据机的划分\n",
    "\n",
    "不平衡数据处理：\n",
    "常见的不平衡数据集处理：\n",
    "    1.金融欺诈\n",
    "    2.疾病监测\n",
    "    3.意图识别的罕见问题\n",
    "常用解决方案：\n",
    "    1.继续收集数据\n",
    "    2.重新采样\n",
    "    3.构造人造数据\n",
    "    4.选取更好模型\n",
    "    5.损失函数/评价指标\n",
    "    \n",
    "ROC曲线（Receiver Operating Characteristics）-->统计学上学的alpha/beta。\n",
    "False Positive Rate当作X-axis，True Positive Rate当作Y-axis？\n",
    "曲线下面积代表性能。\n",
    "\n",
    "回归问题评价准则：MSE（也叫做L2）/MAE/RMSE/etc\n",
    "\n",
    "机器学习评估指标：Clustering。\n",
    "如果有标签，还是做了聚类：Rand Index/混淆矩阵\n",
    "无标签，Davies-Roulding指数（DBI）计算类内距离vs类见距离，轮廊系数（Silhouette Coefficient）\n",
    "\n",
    "机器翻译领域的评估指标BLEU，Bilingual Evaluation Understudy\n",
    "就是看匹配到的词组的个数/总个数（人工的vs机器的）\n",
    "\n",
    "知识蒸馏\n",
    "Teacher Model（Large Neural Network）》Loss》Student Model（简单很多）\n",
    "一直训练使得两个模型的loss差距变小。\n",
    "\n",
    "模型部署方案：\n",
    "Tensorflow-serving：版本管理、不停机升级、高性能\n",
    "Tensorflow-lite：针对移动设备&边缘计算优化\n",
    "\n",
    "同一个patch的数据里，训练集和验证集不要有交集\n",
    "Cross Validation：把验证集的proportion固定，但是具体的内容不固定。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
